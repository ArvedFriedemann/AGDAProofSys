No Title


In this paper the merge of logic programming and proof theory will be discussed in order to create optimal proof systems. The computational basis will be an algorithm using unification, as is often used in logical languages. The algorithm needs a specification of its own implementation, so in this paper it will be described in its own formalism already. The problem that will be solved will subsume the problem of proof search for dependently typed programming languages, as it gives a nice and readable formalism.

Proof search for dependently typed programs looks as follows. Let a type be represented by a term. Each type A has associated to it its proof, encoded as a term (a : A). There is a function type -> that can create a new type from two types A and B, like (f : (a : A) -> (b : B)). This reads as "forall a proving A, b proves B". There is the simple typing rule that says if there is an (a : A) and a function (f : (a' : A) -> (b : B)), that (f a : B), meaning that a proof of an implication is a function transforming proofs of A into proofs of B. Therefore the proof search problem for dependently typed programs can be reduced to saying that given an implication (p : (a1 : A1) -> ... -> (an : An) -> (q : Q)), the goal is to find a term q that is made up of the terms p,a1,...,an that proves Q (splits and termination checking will be covered later). Expressed as a logical program, this looks like


check (_ : T).
--TODO: variable refreshing
(P = (a1 : A1) -> ... -> (an : An) -> (ak a1' ... an' : Q)) =>
(choose
  (ak : (ak1 : Ak1) -> ... -> (akn : Akn) -> (q' : Q))
  from
  [(p : P),(a1 : A1),...,(an : An)]) =>
check (P -> (p : P) -> (ai' : Aki)) forall i =>
  (check (p : P)).

This code essentially chooses a function that's result type unifies with the goal type, and then creates the proofs of its arguments. It can be evaluated by logical languages. The aim is now to use this formulation and an existing search engine to synthesize a better proof strategy. This strategy will later be directly used to speed up the search while it is still running.

In order for this to work, there needs to be a specification of the inference algorithm used. This will come in the form of a predicate infer/2 that describes two adjacent states of computation. It should have some level of determinism, but does not need to fully have it. It can be used for computation using infer_rec like

(infer_rec X X 1).
(infer X Y) => (infer_rec Y Z n) => (infer_rec X Z (suc n)).

This also gives the number of state changes during the inference process for complexity analysis. The state itself will be encoded as a conjunction of parallel, quoted goals. The basics of using proof theory for optimal solving strategies can now be clarified by the following example.
Let (p : P) be some goal. Consider p1 and p2 two possible proofs for P. The proof that should now be taken is the one that propagates the fastest. So the following goals are added:

(curr_state S),
((p1 : P) ^ S = X1), (infer_rec X1 Y1 n1),
((p2 : P) ^ S = X2), (infer_rec X2 Y2 n2),
(n1 < n2 -> p1 = p),
(n2 < n1 -> p2 = p)

So, if from the current state S of the system, branching for p1 is faster than branching for p2, then p1 should be the proof that is taken.
Of course, just putting these rules does not directly make the system faster. In fact, for common deduction systems that evaluate all goal facts without communicating results, this will always be slower because both paths will be evaluated. However, if the KB changes and some of these goals can be evaluated quicker than doing the proof, there is a speed benefit. Furthermore, if the inference algorithm is allowed to occasionally ignore testing both possibilities, it can even still work despite some runtimes not being deducible. These are two problems with one solution each.

The first solution is to modify the KB during the search. This is a generalisation of the clause learning used in SAT and SMT solvers. First, a clause can be added to the KB if it does not shrink the solution space. This can be formulated for a clause C by proving the statement

(infer_rec X Z _) -> (infer_rec (X ^ C) Z' _) -> (Z ~= Z')

Where ~= is some equality metric, e.g. that the same facts can be deduced.
Just adding all possible clauses will be infeasable, therefore a second idea needs to be implemented: A clause C can be added if it is beneficial. A clause can be added or removed if it improves the current search speed. So, it needs to hold that

(infer_rec X Z n1) -> (infer_rec (X ^ C) Z' n2) -> (n2 < n1)
(infer_rec (X ^ C) Z n1) -> (infer_rec X Z' n2) -> (n2 < n1)

for a clause to be added or removed.
Still though, if all possible clauses for which this criterion holds would need to be added, searching for them could slow the process again. For this, a search strategy that can occasionally ignore possibilities needs to be added.


To account for all these specifications, a universal goal needs to be used to create a solving algorithm. Problem with this is the notion of what is considered "fast". Here, a formalisation is used where the possible solutions should be given as a stream, in the order that they can be found the fastest. What is meant by 'can be found the fastest' is: If there was complexity information available on which solution could be found faster, it was used in the search process for prioritisation.



In a fully deterministic machine model, all of the above would be subsumed by correctness of the algorithm, ensuring it optimizes for speed. To fit more with exiting methods for logical programming though, standard inference methods will be used. This means that always all clauses in the KB are consulted (a more deterministic and local machine could choose to ignore some), meaning that reducing the computational effort per step can only be achieved by reducing the number of clauses. Therefore, the KB is actually changed in each deduction step. This process can be described as follows.

Let S be some initial search state. It is made up of the conjecture (p : G), where G = (a1 : A1) -> ... -> (an : An) -> (q : Q), where we call the set {(p : G), (a1 : A1),...,(an : An)} the knowledge base (KB), Q the goal and q the proof or path to Q. When we let the quoted S propagate, we get a (multi) goal (q1 : Q1) ^ ... ^ (qn : Qn), that can be seen as a set of goals each with their own KB. All these goals share each other in their KBs, the termination checker ensures the proof still stays valid. This propagated (quoted) search state is called S'.

Each computational state can derive knowledge from its own representation. For this, there can be a KB of meta rules that derives this information that we will call META. After every propagation, the additional goal (META => (quote S') => S') is added. This can assign variables of S' and trigger new propagations. There are two problems with this approach: First, it can only add knowledge, but not remove any. It can only lead to new assignments, not new KBs. Second, the META knowledge is previously unknown.

To solve the second problem, the META KB will be filled with rules that look at the entire system (including the META propagation itself). When proving that a certain assignment has to be made (e.g. through simulating the system), this places the assignment.

To solve the first problem, there will be an extra structure. After each propagation, the META rules can deduce the next state that is being propagated. As the META-rules invoke propagation themselves, this might not give too many meaningful results. Therefore it is essential, that the META rules can stop propagations from happening. It can stop all non-atomic propagations and deduce the next search state. Which propagations can be stopped needs to be checked when simulating the system.

We assume that in a quoted term, all unassigned variables are exchanged with a variable tag and a constant that is the variables id. There is a predicate unify/4 that takes two terms, creates the unified term, and gives a list of additional assignment changes (so they could be applied to other terms if necessary).
There is a predicate infer_state/2 that does the quoted state transition. Here it is important that the next state contains all splits, so it is a mixture of conjunctions and disjunctions. Deriving bot from a conjunction makes the conjunction bot, deriving bot for all branches in a disjunction does as well, and knowing only one branch is left makes that branch propagate further.
--TODO: Maybe just have a nondeterministic predicate, and some kind of "all" call to it? Then, the next one would only create the clauses needed...maybe on off variables for clauses, so no super meta smth rules are needed




Last but not least, when nothing propagates, some universal search algorithm needs to be employed. This should be just some random search. So every time nothing propagates, the next step is picked at random. This is admissible because if the system could deduce the next step, it would have done so using propagation. Therefore, using random search now is admissible. If memory is not an issue, random search is just continued with a backtracking mechanism. If some memory barrier is hit then the search is done again and again until it succeeds.






.
